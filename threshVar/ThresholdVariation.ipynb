{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72e8eb1-8afa-423c-a129-d34393e275c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random as random\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy.core import read\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064d7eb2-1afa-4e6a-b5d2-e940e1c0c9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 10:49:14.334636: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-14 10:49:14.334958: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "signalmodel = load_model('signalmodelCNN_v3')\n",
    "locmodel = load_model('locmodelCNN_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1267e4cc-e62b-40cb-ab9f-4650152ce049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(trace, p_prob, s_prob):\n",
    "    \n",
    "    ## Things to Specify -- Ensure that they align with trained model\n",
    "    # For rolling averages\n",
    "    roll_short = 25\n",
    "    roll_long = 50\n",
    "\n",
    "    # For location segments\n",
    "    window_step = 20\n",
    "    window_size = 20\n",
    "    \n",
    "    # Step size for CNN\n",
    "    n_steps_sig = 3\n",
    "    n_steps_loc = 2\n",
    "    \n",
    "    # Probability cut-offs\n",
    "    p_prob = p_prob # for p-wave\n",
    "    s_prob = s_prob # for signal\n",
    "    \n",
    "    ## Reading in Trace and Splitting Channels\n",
    "    sig_trace = trace.normalize()\n",
    "    \n",
    "    samp_rate = sig_trace.stats.sampling_rate\n",
    "    start_time = sig_trace.stats.starttime\n",
    "    \n",
    "    sigs = sig_trace.data\n",
    "    \n",
    "    sig_df = pd.DataFrame(sigs, columns = [\"trace\"])\n",
    "    \n",
    "    sigfeatures = []\n",
    "    \n",
    "    ## Calculating various features needed for the signal model\n",
    "    tr = sig_df[\"trace\"]\n",
    "    mag = abs(tr)\n",
    "    d = {\"trace\":tr, \"magnitude\":mag}\n",
    "    temp_df = pd.DataFrame(data = d)\n",
    "    \n",
    "    temp_df[\"STA\"] = temp_df[\"magnitude\"].rolling(roll_short).mean()\n",
    "    temp_df[\"LTA\"] = temp_df[\"magnitude\"].rolling(roll_long).mean()\n",
    "    temp_df[\"RAV\"] = temp_df[\"STA\"]/temp_df[\"LTA\"]\n",
    "    temp_df[\"STV\"] = temp_df[\"magnitude\"].rolling(roll_short).var()\n",
    "    temp_df[\"LTV\"] = temp_df[\"magnitude\"].rolling(roll_long).var()\n",
    "\n",
    "    temp_df.dropna(inplace = True)\n",
    "    sigfeatures.append(temp_df.values)\n",
    "    \n",
    "    sigfeatures = np.array(sigfeatures)\n",
    "    n_timesteps, n_features, n_outputs = sigfeatures.shape[1], sigfeatures.shape[2], 2\n",
    "    n_length = int(n_timesteps/n_steps_sig)\n",
    "\n",
    "    sigfeatures1 = sigfeatures.reshape((sigfeatures.shape[0], n_steps_sig, n_length, n_features))\n",
    "    \n",
    "    ## Predicting whether or not there is a pwave in the trace\n",
    "    is_sig = signalmodel.predict(sigfeatures1)[0][1]\n",
    "\n",
    "    locfeatures = []\n",
    "\n",
    "    ## If there is a pwave in the trace, continue to find location of pwave\n",
    "    start_ind = 0\n",
    "    end_ind = start_ind + window_size\n",
    "\n",
    "    while end_ind < (1000 - roll_long):\n",
    "        trwindow = temp_df[\"trace\"].iloc[start_ind:end_ind]\n",
    "        magwindow = temp_df[\"magnitude\"].iloc[start_ind:end_ind]\n",
    "        ravwindow = temp_df[\"RAV\"].iloc[start_ind:end_ind]\n",
    "        stvwindow = temp_df[\"STV\"].iloc[start_ind:end_ind]\n",
    "        ltvwindow = temp_df[\"LTV\"].iloc[start_ind:end_ind]\n",
    "\n",
    "        window_data = {\"trace\": trwindow, \"magnitude\": magwindow,\n",
    "                            \"RAV\": ravwindow, \"STV\": stvwindow, \"LTV\": ltvwindow}\n",
    "\n",
    "        window_df = pd.DataFrame(data = window_data)\n",
    "\n",
    "        locfeatures.append(window_df.values)\n",
    "\n",
    "        start_ind += window_step\n",
    "        end_ind = start_ind + window_size\n",
    "\n",
    "    locfeatures = np.array(locfeatures)\n",
    "    n_timesteps, n_features, n_outputs = locfeatures.shape[1], locfeatures.shape[2], 2\n",
    "    n_length = int(n_timesteps/n_steps_loc)\n",
    "    \n",
    "    locfeatures1 = locfeatures.reshape((locfeatures.shape[0], n_steps_loc, n_length, n_features))\n",
    "    \n",
    "    \n",
    "    prob_vec = locmodel.predict(locfeatures1)[:,1]\n",
    "    \n",
    "    # Since we know if there is a p-wave, it will be in the last 3 seconds:\n",
    "    end_ind = len(prob_vec)\n",
    "    beg_ind = len(prob_vec) - int(3*samp_rate/window_size + 1)\n",
    "    p_segment = beg_ind + np.where(prob_vec[beg_ind:end_ind] == max(prob_vec[beg_ind:end_ind]))[0][0]\n",
    "        \n",
    "    tick_delta = p_segment*window_step + 0.5*window_size + (roll_long - 1)\n",
    "        \n",
    "    time_delta = (tick_delta)/samp_rate\n",
    "    p_time = start_time + time_delta\n",
    "        \n",
    "    if (is_sig >= s_prob)|(max(prob_vec[beg_ind:end_ind]) > p_prob):\n",
    "        return p_time\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0275eaeb-8efe-4309-8bdc-b2799af209f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all filenames\n",
    "datapath = \"validation_data\"\n",
    "valid_filenames = [f for f in glob.glob(datapath + \"/*/*\")]\n",
    "number_of_files = len(valid_filenames)\n",
    "number_of_noise = len([f for f in valid_filenames if \"_N\" in f])\n",
    "number_of_pwave = number_of_files-number_of_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5101aaa-f674-4b7f-b2bd-2370da4cc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_samples(valid_filenames, p_prob, s_prob, seed):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    # set variables\n",
    "    accuracy = .5 # max time difference in seconds\n",
    "    p_win = (.5, 3) # setting limits for P-wave \n",
    "    sampling_rate = 31.25\n",
    "    min_snr = 1.5\n",
    "    hit = 0; miss = 0; false_alarm = 0; correct_rejection = 0\n",
    "    hit_accuracy = []\n",
    "    \n",
    "    for f in valid_filenames:\n",
    "\n",
    "        # read in the file\n",
    "        st = read(f)\n",
    "        cut = int((random.random()*p_win[1]+p_win[0])*sampling_rate)\n",
    "\n",
    "        # iterate over traces in mseed files\n",
    "        for tr in st:\n",
    "\n",
    "            # there was a comment raised during one of the sessions that some p-waves have very low signal-to-noise ratio\n",
    "            # here I require all p-waves to have snr 1.5 or greater\n",
    "            # snr is calcuated as a ratio of sums of abs values of waveforms 1s before and 1s after p-wave arrival\n",
    "            snr = sum(abs(tr.data[1000:1032]))/sum(abs(tr.data[1000-32:1000]))\n",
    "\n",
    "            # in case of small snr, just print a message\n",
    "            if \"_P\" in f and snr<=min_snr:\n",
    "                abc = 1\n",
    "                #print(\"  Channel: {}, passing, not high-enough P wave S/N ratio ({:4.2f})\".format(tr.stats.channel, snr))      \n",
    "\n",
    "            # otherwise do everything\n",
    "            else:\n",
    "                tr.data = tr.data[cut:1000+cut]\n",
    "\n",
    "                # set correct answers\n",
    "                if \"_N\" in f:\n",
    "                    # if it is a noise segment, the correct answer is None\n",
    "                    correct_answer = None\n",
    "                else:\n",
    "                    # if it is a p-wave segment, the correct answer is the p-wave arrival time (UTCDateTime format)\n",
    "                    correct_answer = tr.stats.starttime + (1000-cut)/tr.stats.sampling_rate\n",
    "\n",
    "                prediction = predict(tr, p_prob, s_prob)\n",
    "\n",
    "                # Evaluation logic\n",
    "                # noise segment, no p-wave detected\n",
    "                if prediction is None and correct_answer is None:\n",
    "                    correct_rejection += 1\n",
    "\n",
    "                # p-wave segment but no detection\n",
    "                elif prediction is None and correct_answer is not None:\n",
    "                    miss += 1\n",
    "\n",
    "                # p-wave falsely detected in noise segment\n",
    "                elif prediction is not None and correct_answer is None:\n",
    "                    false_alarm += 1\n",
    "\n",
    "                # p-wave detected in p-wave segment\n",
    "                else:\n",
    "                    # evaluate if the detection is accurate enough, if so it is a hit...\n",
    "                    if abs(correct_answer-prediction)<=accuracy:\n",
    "                        hit += 1\n",
    "                        hit_accuracy.append(correct_answer-prediction)\n",
    "\n",
    "                    # ...else it is unfortunately a miss.\n",
    "                    else:\n",
    "                        miss += 1\n",
    "                        hit_accuracy.append(correct_answer-prediction)\n",
    "\n",
    "    # calculate the stats\n",
    "    precision = hit/(hit+false_alarm)\n",
    "    recall = hit/(hit+miss)\n",
    "    f1score = (2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    return(f1score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac0a64c-f963-4da3-b3aa-d43f89317faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_vec = np.linspace(1, 10, 10)\n",
    "seed_vec = [1, 5, 10]\n",
    "p_probs = np.linspace(0.1, 0.2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04610aa-7059-42a4-90c4-6ac3c4eaf657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-S 0.1 - 0.1 : 0.892388316617\n",
      "P-S 0.12 - 0.1 : 0.900882375344\n",
      "P-S 0.14 - 0.1 : 0.903743433941\n",
      "P-S 0.16 - 0.1 : 0.906532653442\n",
      "P-S 0.18 - 0.1 : 0.911210757298\n"
     ]
    }
   ],
   "source": [
    "s_prob = 0.1\n",
    "for p_prob in p_probs:\n",
    "    seed_f1 = []\n",
    "    for seed in seed_vec:\n",
    "        f1 = f1_samples(valid_filenames, p_prob, s_prob, seed)\n",
    "        seed_f1.append(f1)\n",
    "        \n",
    "    avg_f1 = np.mean(seed_f1)\n",
    "        \n",
    "    print(\"P-S\", p_prob, \"-\", s_prob, \":\", avg_f1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32381406-4b58-43b4-85fe-2927b2029733",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_probs = np.linspace(0.2, 0.3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91018278-4220-46e0-9405-29444f8fe699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_prob in p_probs:\n",
    "    seed_f1 = []\n",
    "    for seed in seed_vec:\n",
    "        f1 = f1_samples(valid_filenames, p_prob, s_prob, seed)\n",
    "        seed_f1.append(f1)\n",
    "        \n",
    "    avg_f1 = np.mean(seed_f1)\n",
    "        \n",
    "    print(\"P-S\", p_prob, \"-\", s_prob, \":\", avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b8377-d8e2-4d6d-84d8-e6ee79f27f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
